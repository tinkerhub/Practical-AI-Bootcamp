{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ships-vs-Truck.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rgRCGDHz2pCS"
      },
      "source": [
        "!wget https://github.com/Harikrishnan6336/ShipORTruck-ImageClassifier/raw/main/ML_model/dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9kZvYZvh1WJ"
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWSRn8Iwh1-J"
      },
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nx1uUVyfY3g"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, dir_name):\n",
        "        self.dir_name = dir_name\n",
        "        self.labels,self.images = self.load_data()\n",
        "        \n",
        "    # To load images and labels for dataloader\n",
        "    def load_data(self):\n",
        "        labels={}\n",
        "        images = {}\n",
        "        # Composes Resize transform, Here resize transforms the input image to size (256, 256)\n",
        "        resize = transforms.Compose([transforms.Resize((256,256))])\n",
        "        main_dir = os.listdir(os.path.join(\"dataset\",self.dir_name))\n",
        "        count = 0\n",
        "        # traversing through the categories/directories(here SHIP and TRUCK) in the main directory\n",
        "        for i,dir in enumerate(main_dir):\n",
        "            images_list = os.listdir(os.path.join(\"dataset\",self.dir_name,dir))\n",
        "            # traversing through the images in each directory/category\n",
        "            local_cnt = 0\n",
        "            for img in images_list: \n",
        "                labels[count] = i\n",
        "                img_path = os.path.join(\"dataset\",self.dir_name,dir,img)\n",
        "                image = Image.open(img_path)\n",
        "                image = ToTensor()(image)\n",
        "                images[count] = resize(image)\n",
        "                count += 1\n",
        "                local_cnt += 1\n",
        "        return labels,images\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    # To return x,y values in each iteration over dataloader as batches.\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.images[idx],\n",
        "            self.labels[idx],\n",
        "        )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQQfpS7MoInS"
      },
      "source": [
        "dataset = Dataset(\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5A_wvNuy4uj"
      },
      "source": [
        "validdataset = Dataset(\"valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SeR8-4YfkUQ"
      },
      "source": [
        "# Model Architecture\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1= nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)\n",
        "        self.conv2= nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
        "        self.conv3= nn.Conv2d(in_channels=12,out_channels=24,kernel_size=5)\n",
        "        self.conv4= nn.Conv2d(in_channels=24,out_channels=48,kernel_size=5)\n",
        "        \n",
        "        # Fully Connected layers\n",
        "        self.fc1 = nn.Linear(in_features=48*12*12,out_features=240)\n",
        "        self.fc2 = nn.Linear(in_features=240,out_features=120)\n",
        "        self.out = nn.Linear(in_features=120,out_features=2)\n",
        "        \n",
        "        \n",
        "    def forward(self,t):\n",
        "        t = t\n",
        "        \n",
        "        t=self.conv1(t)\n",
        "        t=F.relu(t)\n",
        "        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
        "        \n",
        "        \n",
        "        t=self.conv2(t)\n",
        "        t=F.relu(t)\n",
        "        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
        "\n",
        "        t=self.conv3(t)\n",
        "        t=F.relu(t)\n",
        "        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
        "\n",
        "        t=self.conv4(t)\n",
        "        t=F.relu(t)\n",
        "        t=F.max_pool2d(t,kernel_size = 2, stride = 2)\n",
        "        \n",
        "        t=t.reshape(-1,48*12*12)\n",
        "        t=self.fc1(t)\n",
        "        t=F.relu(t)\n",
        "        t=self.fc2(t)\n",
        "        t=F.relu(t)\n",
        "        \n",
        "        t=self.out(t)\n",
        "        \n",
        "        return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keebdG9UfvAY"
      },
      "source": [
        "model = Network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOdLR8FB5cAz"
      },
      "source": [
        "print(\"Model structure: \", model, \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_lhmHSM4MDp"
      },
      "source": [
        "def train(dataset,validdataset, model):\n",
        "    model.train()\n",
        "\n",
        "    # dataloader in pytorch to load validation and train dataset\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,shuffle=True)\n",
        "    valdataloader = torch.utils.data.DataLoader(validdataset, batch_size=32,shuffle=True)\n",
        "\n",
        "    # Defining the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    num_of_epochs = 25\n",
        "    epochs = []\n",
        "    losses = []\n",
        "    accuracy = []\n",
        "    for epoch in range(num_of_epochs):\n",
        "        cnt = 0\n",
        "        tot_loss = 0\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            # Sets the gradients of all optimized tensors to zero\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x)\n",
        "            # Compute loss (here CrossEntropyLoss)\n",
        "            loss = F.cross_entropy(y_pred,y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        size = len(valdataloader.dataset)\n",
        "        correct = 0\n",
        "        for batch, (x, y) in enumerate(valdataloader):\n",
        "            # Sets the gradients of all optimized tensors to zero\n",
        "            optimizer.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(x)\n",
        "                # Compute loss (here CrossEntropyLoss)\n",
        "                loss = F.cross_entropy(y_pred,y)\n",
        "                \n",
        "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            tot_loss+=loss.item()\n",
        "\n",
        "        # accuracy.append((correct*100))\n",
        "        epochs.append(epoch)\n",
        "        losses.append(tot_loss)\n",
        "        correct /= size\n",
        "        accuracy.append(correct*100)\n",
        "        print(\"Epoch \",epoch,\" Accuracy \",(100*correct),\"% loss: \",tot_loss)\n",
        "        # Save model after each epoch, so that we can choose the best model, later\n",
        "        torch.save(model.state_dict(), \"model_ep\"+str(epoch+1)+\".pth\")\n",
        "\n",
        "        # Plot a Validation Accuracy vs Epochs graph \n",
        "    plt.plot(epochs, accuracy, color='green', linewidth = 3, \n",
        "         marker='o', markerfacecolor='blue', markersize=8) \n",
        "    plt.xlabel('epochs ---->',color='m',fontsize='xx-large' ) \n",
        "    plt.ylabel('Val Accuracy (in %) ------>',color='m',fontsize='xx-large') \n",
        "    axes = plt.gca()        # 'gca' - get current axes\n",
        "    axes.set_facecolor('c') #'c' - cyan (color name)\n",
        "    axes.tick_params(axis='y', which='both', colors='tomato')\n",
        "    axes.tick_params(axis='x', which='both', colors='#20ff14')\n",
        "    plt.title(\"Validation Accuracy vs Epoch\",color='m',fontsize='xx-large')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc6_I9Wef-l4"
      },
      "source": [
        "train(dataset,validdataset, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVu_nYn7gBXG"
      },
      "source": [
        "# Saving labels to label value as a json\n",
        "main_dir = os.listdir(os.path.join(\"dataset\",\"train\"))\n",
        "reference = {}\n",
        "for i,dir in enumerate(main_dir):\n",
        "    reference[dir]=i\n",
        "print(reference)\n",
        "with open('labels.json', 'wb') as iw:\n",
        "    pickle.dump(reference, iw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKalBn1bgD6x"
      },
      "source": [
        "#Save the trained model\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pco_HAPgFll"
      },
      "source": [
        "# prediction function to test\n",
        "def predict(img_path):\n",
        "    image = Image.open(img_path)\n",
        "    image = ToTensor()(image)\n",
        "    resize = transforms.Compose([transforms.Resize((256,256))])\n",
        "    y_result = model(resize(image).unsqueeze(0))\n",
        "    result_idx = y_result.argmax(dim=1)\n",
        "    for key,value in reference.items():\n",
        "        if(value==result_idx):\n",
        "            print(value)\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NZOuSoRKTaN"
      },
      "source": [
        "predict(\"<IMG_PATH_HERE>\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}